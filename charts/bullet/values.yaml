global:
  imageRegistry:
  imagePullSecrets: []
  nameOverride:
  fullnameOverride:
  commonLabels: {}
  commonAnnotations: {}

ui:
  configDir: /usr/local/var/bullet/ui/config
  config:
    queryHost: http://localhost:9999
    schemaHost: http://localhost:9999
  image:
    repository: sketchbench/bullet-ui
    tag: "1.1.0"
    pullPolicy: IfNotPresent
  podAnnotations: {}
  podSecurityContext: {}
  securityContext: {}
  nodeSelector: {}
  tolerations: []
  affinity: {}
  resources: {}
  autoscaling:
    enabled: false
  replicaCount: 1
  service:
    type: ClusterIP
    port: 8800
webservice:
  configDir: /bullet/configs
  config:
    bullet:
      pubsub:
        kafka:
          request:
            topic:
              name: bullet.requests
          response:
            topic:
              name: bullet.responses
      query:
        aggregation:
          max:
            size: 1024
  image:
    repository: sketchbench/bullet-service
    tag: "1.1.0"
    pullPolicy: IfNotPresent
  podAnnotations: {}
  podSecurityContext: {}
  securityContext: {}
  nodeSelector: {}
  tolerations: []
  affinity: {}
  resources: {}
  autoscaling:
    enabled: false
  replicaCount: 1
  service:
    type: ClusterIP
    port: 9999
sparkBackend:
  jar: /opt/bitnami/spark/jars/bullet-spark-standalone.jar
  otherJars: /opt/bitnami/spark/jars/bullet-kafka-fat.jar,/opt/bitnami/spark/jars/bullet-dsl.jar,/opt/bitnami/spark/jars/bullet-spark-example.jar
  hdfsUser: hadoop
  configDir: /bullet/configs
  schemaDir: /bullet/schemas
  metrics:
    enabled: false
    podMonitor:
      enabled: false
      extraMetricsEndpoints: []
      namespace: ""
      interval: 30s
      scrapeTimeout:
    graphiteExporter:
      enabled: false
      periodSeconds: 30
  config:
    # See https://github.com/bullet-db/bullet-spark/blob/master/src/main/resources/bullet_spark_defaults.yaml
    ### Bullet ###
    bullet:
      ### Bullet Spark ###
      spark:
        data:
          producer:
            class:
              name: com.yahoo.bullet.spark.examples.RandomProducer
            parallelism: 1
        dsl:
          data:
            producer:
              enable: false
          deserializer:
            enable: false
        batch:
          duration:
            ms: 1000
        receiver:
          query:
            block:
              size: 1
            coalesce:
              partitions: 10
        checkpoint:
          dir: /spark/checkpoints
        recover:
          from:
            checkpoint:
              enable: false
        app:
          name: "BulletSparkStreamingJob"
        metrics:
          enabled: false
        filter:
          partition:
            parallel:
              mode:
                enabled: false
                parallelism: 4
                min:
                  query:
                    threshold: 10
        query:
          union:
            checkpoint:
              duration:
                multiplier: 10
        join:
          checkpoint:
            duration:
              multiplier: 10
        loop:
          pubsub:
            # todo: fix .Values.bullet.sparkBackend.config.bullet.spark.loop.pubsub.overrides
            overrides: {}
      ### Bullet DSL (Kafka) ###
      dsl:
        connector:
          class:
            name:
          read:
            timeout:
              ms: 0
          async:
            commit:
              enable: true
          kafka:
            topics:
              - ""
            start:
              at:
                end:
                  enable: false
            bootstrap:
              servers:
                - localhost:9092
            group:
              id: "bullet-consumer-group"
            key:
              deserializer: "org.apache.kafka.common.serialization.StringDeserializer"
            value:
              deserializer: "org.apache.kafka.common.serialization.StringDeserializer"
            enable:
              auto:
                commit: true
        converter:
          class:
            name:
          schema:
            file: /bullet/schemas/dsl_schema.json
            type:
              check:
                enable: false
        deserializer:
          class:
            name:
      ### Query PubSub ###
      pubsub:
        context:
          name: QUERY_PROCESSING
        class:
          name: com.yahoo.bullet.kafka.KafkaPubSub
        kafka:
          request:
            topic:
              name: "bullet.requests"
          response:
            topic:
              name: "bullet.responses"
      ### Bullet Core ###
      query:
        aggregation:
          raw:
            max:
              size: 500
          count:
            distinct:
              sketch:
                entries: 16384
          group:
            sketch:
              entries: 1024
          distribution:
            sketch:
              entries: 1024
            max:
              points: 200
            generated:
              points:
                rounding: 6
          top:
            k:
              sketch:
                entries: 1024
                error:
                  type: "NFN"
      result:
        metadata:
          enable: true
      record:
        provider:
          class:
            name: com.yahoo.bullet.record.simple.UntypedSimpleBulletRecordProvider
    ### Spark Streaming ###
    spark:
      serializer: org.apache.spark.serializer.KryoSerializer
      closure:
        serializer: org.apache.spark.serializer.KryoSerializer
      streaming:
        stopGracefullyOnShutdown: true
        receiver:
          writeAheadLog:
            enable: false
        driver:
          writeAheadLog:
            allowBatching: false
  dsl:
    schema: ""
  image:
    repository: sketchbench/bullet-spark-3.0
    tag: "1.0.4"
    pullPolicy: IfNotPresent
  imagePullSecrets: []
  podAnnotations: {}
  podSecurityContext: {}
  securityContext: {}
  nodeSelector: {}
  tolerations: []
  affinity: {}
  resources: {}
  service:
    type: ClusterIP
    port: 4040
  driver:
    port: 4041
    blockManagerPort: 4042
    confs:
      - --conf
      - spark.cores.max=6
      - --conf
      - spark.executor.cores=1
      - --conf
      - spark.executor.memory=2G

### External Dependencies ###
spark:
  enabled: true
  image:
    repository: sketchbench/bullet-spark-3.0
    tag: "1.0.4"
    pullPolicy: IfNotPresent
  worker:
    replicaCount: 3
    coreLimit: 2
    resources:
      requests:
        memory: "5Gi"
        cpu: "2.25"
      limits:
        memory: "5Gi"
        cpu: "2.25"
  master:
    resources:
      requests:
        memory: "5Gi"
        cpu: "2.25"
      limits:
        memory: "5Gi"
        cpu: "2.25"

hdfs:
  enabled: false
  config:
    hdfsSite:
      # https://github.com/gchq/gaffer-docker/pull/152
      dfs.namenode.datanode.registration.ip-hostname-check: false

pubsubMonit:
  enabled: true
  nameOverride: pubsub-monit
  timezone: America/Los_Angeles
  deployment:
    containerName: pubsub-monit
  config:
    kafka:
      connections:
        - pubsub:9092
      properties:
        content: ""
      truststore:
        content: ""
      keystore:
        content: ""
    jvm:
      - -Xms128M
      - -Xmx256M
      - -Xss180K
      - -XX:-TieredCompilation
      - -XX:+UseStringDeduplication
      - -noverify
