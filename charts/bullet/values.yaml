bullet:
  nameOverride: ""
  fullnameOverride: ""
  serviceAccount:
    create: false
    name: ""
  ##### Bullet components based on templates #####
  ui:
    configDir: /usr/local/var/bullet/ui/config
    config:
      queryHost: http://localhost:9999
      schemaHost: http://localhost:9999
    image:
      repository: sketchbench/bullet-ui
      tag: latest
      pullPolicy: IfNotPresent
    imagePullSecrets: []
    podAnnotations: {}
    podSecurityContext: {}
    securityContext: {}
    nodeSelector: {}
    tolerations: []
    affinity: {}
    resources: {}
    autoscaling:
      enabled: false
    replicaCount: 1
    service:
      type: ClusterIP
      port: 8800
  webservice:
    configDir: /bullet/configs
    config:
      bullet:
        pubsub:
          kafka:
            request:
              topic:
                name: bullet.requests
            response:
              topic:
                name: bullet.responses
        query:
          aggregation:
            max:
              size: 1024
    image:
      repository: sketchbench/bullet-service
      tag: latest
      pullPolicy: IfNotPresent
    imagePullSecrets: []
    podAnnotations: {}
    podSecurityContext: {}
    securityContext: {}
    nodeSelector: {}
    tolerations: []
    affinity: {}
    resources: {}
    autoscaling:
      enabled: false
    replicaCount: 1
    service:
      type: ClusterIP
      port: 9999
  sparkBackend:
    jar: /opt/bitnami/spark/jars/bullet-spark-standalone.jar
    otherJars: /opt/bitnami/spark/jars/bullet-kafka-fat.jar,/opt/bitnami/spark/jars/bullet-dsl-fat.jar,/opt/bitnami/spark/jars/bullet-spark-example.jar
    hdfsUser: hdfs
    configDir: /bullet/configs
    schemaDir: /bullet/schemas
    executorCores: 2
    executorMemory: 3G
    config:
      # See https://github.com/bullet-db/bullet-spark/blob/master/src/main/resources/bullet_spark_defaults.yaml
      ### Bullet ###
      bullet:
        ### Bullet Spark ###
        spark:
          data:
            producer:
              class:
                name: com.yahoo.bullet.spark.examples.RandomProducer
              parallelism: 1
          dsl:
            data:
              producer:
                enable: false
            deserializer:
              enable: false
          batch:
            duration:
              ms: 1000
          receiver:
            query:
              block:
                size: 1
              coalesce:
                partitions: 10
          checkpoint:
            dir: /spark/checkpoints
          recover:
            from:
              checkpoint:
                enable: false
          app:
            name: "BulletSparkStreamingJob"
          metrics:
            enabled: false
          filter:
            partition:
              parallel:
                mode:
                  enabled: false
                  parallelism: 4
                  min:
                    query:
                      threshold: 10
          query:
            union:
              checkpoint:
                duration:
                  multiplier: 10
          join:
            checkpoint:
              duration:
                multiplier: 10
          loop:
            pubsub:
              # todo: fix .Values.bullet.sparkBackend.config.bullet.spark.loop.pubsub.overrides
              overrides: {}
        ### Bullet DSL (Kafka) ###
        dsl:
          connector:
            class:
              name:
            read:
              timeout:
                ms: 0
            async:
              commit:
                enable: true
            kafka:
              topics:
                - ""
              start:
                at:
                  end:
                    enable: false
              bootstrap:
                servers: "localhost:9092"
              group:
                id: "bullet-consumer-group"
              key:
                deserializer: "org.apache.kafka.common.serialization.StringDeserializer"
              value:
                deserializer: "org.apache.kafka.common.serialization.ByteArrayDeserializer"
              enable:
                auto:
                  commit: true
          converter:
            class:
              name:
            schema:
              file: /bullet/schemas/dsl_schema.json
              type:
                check:
                  enable: false
          deserializer:
            class:
              name:
        ### Query PubSub ###
        pubsub:
          context:
            name: QUERY_PROCESSING
          class:
            name: com.yahoo.bullet.kafka.KafkaPubSub
          kafka:
            bootstrap:
              servers: "bullet-pubsub:9092"
            request:
              topic:
                name: "bullet.requests"
            response:
              topic:
                name: "bullet.responses"
        ### Bullet Core ###
        query:
          aggregation:
            raw:
              max:
                size: 500
            count:
              distinct:
                sketch:
                  entries: 16384
            group:
              sketch:
                entries: 1024
            distribution:
              sketch:
                entries: 1024
              max:
                points: 200
              generated:
                points:
                  rounding: 6
            top:
              k:
                sketch:
                  entries: 1024
                  error:
                    type: "NFN"
        result:
          metadata:
            enable: true
        record:
          provider:
            class:
              name: com.yahoo.bullet.record.simple.UntypedSimpleBulletRecordProvider
      ### Spark Streaming ###
      spark:
        serializer: org.apache.spark.serializer.KryoSerializer
        closure:
          serializer: org.apache.spark.serializer.KryoSerializer
        streaming:
          stopGracefullyOnShutdown: true
          receiver:
            writeAheadLog:
              enable: false
          driver:
            writeAheadLog:
              allowBatching: false
    dsl:
      schema: ""
    image:
      repository: sketchbench/bullet-spark
      tag: latest
      pullPolicy: Never
    imagePullSecrets: []
    podAnnotations: {}
    podSecurityContext: {}
    securityContext: {}
    nodeSelector: {}
    tolerations: []
    affinity: {}
    resources: {}
    service:
      type: ClusterIP
      port: 4040
    driver:
      port: 4041
      blockManagerPort: 4042
  dataIngestionTester:
    enabled: false
    topic: sketchbench-test
    numberMessages: 0 # unlimited
    maxWaitingTime: 0.5 # seconds
    image:
      repository: sketchbench/sketchbench-data-ingestion-tester
      tag: latest
      pullPolicy: IfNotPresent
    imagePullSecrets: []
    podAnnotations: {}
    podSecurityContext: {}
    securityContext: {}
    nodeSelector: {}
    tolerations: []
    affinity: {}
    resources: {}
##### Other Bullet components #####
# Apache Spark (Streaming)
spark:
  image:
    repository: sketchbench/bullet-spark
    tag: latest
    pullPolicy: Never
  worker:
    replicaCount: 3
    coreLimit: 3
# Apache Kafka as Bullet PubSub
pubsub:
  fullnameOverride: bullet-pubsub
  zookeeper:
    enabled: false
  externalZookeeper:
    servers:
      - bullet-pubsub-zk
# Zookeeper as persistency for Apache Kafka (Bullet PubSub)
pubsub-zk:
  fullnameOverride: bullet-pubsub-zk
# Kafdrop as monitoring tool for Apache Kafka (Bullet PubSub)
pubsub-monit:
  timezone: America/Los_Angeles
  config:
    kafka:
      connections:
        - bullet-pubsub:9092
      properties:
        content: ""
      truststore:
        content: ""
      keystore:
        content: ""
    jvm:
      - -Xms128M
      - -Xmx256M
      - -Xss180K
      - -XX:-TieredCompilation
      - -XX:+UseStringDeduplication
      - -noverify
# Apache Kafka as Bullet Data Ingestion (Data Interface)
data-ingestion:
  fullnameOverride: bullet-data-ingestion
  zookeeper:
    enabled: false
  externalZookeeper:
    servers:
      - bullet-data-ingestion-zk
# Zookeeper as persistency for Apache Kafka (Bullet Data Ingestion)
data-ingestion-zk:
  fullnameOverride: bullet-data-ingestion-zk
# Kafdrop as monitoring tool for Apache Kafka (Bullet PubSub)
data-ingestion-monit:
  timezone: America/Los_Angeles
  config:
    kafka:
      connections:
        - bullet-data-ingestion:9092
      properties:
        content: ""
      truststore:
        content: ""
      keystore:
        content: ""
    jvm:
      - -Xms128M
      - -Xmx256M
      - -Xss180K
      - -XX:-TieredCompilation
      - -XX:+UseStringDeduplication
      - -noverify
